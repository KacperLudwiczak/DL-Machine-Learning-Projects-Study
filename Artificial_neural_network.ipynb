{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KacperLudwiczak/DL-Machine-Learning-Projects-Study/blob/main/Artificial_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkJoQBkUIHC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaTwK7ojXr2F",
        "outputId": "e730ff1d-e1d2-4571-fc6e-b7d20fcb4a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.11.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUkhkMfU4wq"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap77DM5MJQ23",
        "outputId": "50afd750-f67c-4316-cc06-f29b6a9ea1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVYNKSX9JYrn",
        "outputId": "7b2c4dd8-ba94-47e0-c665-d0d1fa85bec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2])\n",
        "\n",
        "# Ten fragment kodu wykorzystuje klasę LabelEncoder z biblioteki Scikit-learn (sklearn) do kodowania zmiennych kategorycznych w trzeciej kolumnie danych wejściowych X.\n",
        "# Pierwsza linia importuje klasę LabelEncoder z modułu sklearn.preprocessing.\n",
        "# Druga linia tworzy instancję klasy LabelEncoder i przypisuje ją do zmiennej le.\n",
        "# Trzecia linia stosuje metodę fit_transform() obiektu le do trzeciej kolumny danych wejściowych X, co koduje zmienne kategoryczne na numeryczne etykiety. Zakodowane wartości zastępują oryginalne wartości kategoryczne w trzeciej kolumnie X.\n",
        "# Należy zauważyć, że klasa LabelEncoder jest zwykle używana do kodowania zmiennych kategorycznych z dwoma lub więcej poziomami. Jeśli zmienna w trzeciej kolumnie X jest binarna, tzn. ma tylko dwa poziomy, możesz użyć klasy BinaryEncoder lub OneHotEncoder."
      ],
      "metadata": {
        "id": "upm1ETyIJ562"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LEdtGz1KS-l",
        "outputId": "d7f0bf68-9143-464f-b172-d69d470773f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "# Ten fragment kodu wykorzystuje klasę ColumnTransformer z biblioteki Scikit-learn (sklearn) do przekształcenia jednej kolumny danych wejściowych X za pomocą klasy OneHotEncoder.\n",
        "# Pierwsza linia importuje klasę ColumnTransformer i klasę OneHotEncoder z modułu sklearn.compose i sklearn.preprocessing.\n",
        "# Druga linia tworzy instancję klasy ColumnTransformer i przypisuje ją do zmiennej ct. W argumencie transformers określa się listę krotek, w których pierwszym elementem jest nazwa transformatora (w tym przypadku 'encoder'), drugim elementem jest instancja transformatora (OneHotEncoder()), a trzecim elementem jest indeks kolumny (1), którą chcemy przekształcić.\n",
        "# Trzecia linia stosuje metodę fit_transform() obiektu ct do danych wejściowych X, co przekształca kolumnę indeksowaną przez 1 na macierz binarną (dummy matrix) z kodowaniem \"jedynkowym\" (one-hot encoding). Argument remainder='passthrough' powoduje, że pozostałe kolumny danych wejściowych są przekazywane bez zmian.\n",
        "# Czwarta linia przypisuje nową przetworzoną macierz danych X do zmiennej X, która jest typu ndarray.\n",
        "\n",
        "# Każda z funkcji użyta w powyższych kodach ma swoje specyficzne zastosowanie.\n",
        "# Funkcja LabelEncoder z biblioteki Scikit-learn jest używana do kodowania zmiennych kategorycznych z dwoma lub więcej poziomami na wartości numeryczne. Dzięki temu można przekształcić dane kategoryczne na format, który może być używany przez algorytmy uczenia maszynowego, które wymagają danych numerycznych.\n",
        "# Funkcja OneHotEncoder z biblioteki Scikit-learn służy do kodowania zmiennych kategorycznych w taki sposób, aby stworzyć macierz binarną, która reprezentuje każde z wartości kategorycznych jako wektor 0/1. Ten sposób kodowania umożliwia zachowanie pełnej informacji o danych kategorycznych, ale zwiększa rozmiar zbioru danych.\n",
        "# Klasa ColumnTransformer z biblioteki Scikit-learn pozwala na przekształcanie różnych kolumn w różny sposób, np. zastosowanie różnych transformatorów na różnych kolumnach. W powyższym kodzie wykorzystano ją, aby przekształcić tylko jedną kolumnę danych, pozostawiając pozostałe kolumny bez zmian.\n",
        "# W zależności od potrzeb i charakterystyki danych, różne funkcje i klasy z biblioteki Scikit-learn mogą być stosowane w celu przetwarzania i transformacji danych przed ich wykorzystaniem w algorytmach uczenia maszynowego."
      ],
      "metadata": {
        "id": "d1itN2sMKsqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBV0xtdaLE5H",
        "outputId": "64369c31-eb4e-4a31-92b1-31d34160aff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-TDt0Y_XEfc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCrE00rV8Sk"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "# Ten fragment kodu tworzy instancję klasy Sequential z biblioteki TensorFlow Keras.\n",
        "# Obiekt tej klasy służy do tworzenia sekwencyjnych modeli sieci neuronowych, w których warstwy są układane jedna po drugiej w kolejności, w jakiej są definiowane. To znaczy, wyjście jednej warstwy jest wejściem do następnej warstwy.\n",
        "# W sekwencyjnym modelu każda warstwa sieci neuronowej ma dokładnie jeden tensor wejściowy i jeden tensor wyjściowy. Przykładowo, sekwencyjny model może składać się z kilku warstw konwolucyjnych, warstw MaxPooling, warstw Dropout, warstw Flatten i warstwy w pełni połączonej (Dense).\n",
        "# Po utworzeniu instancji Sequential można dodawać kolejne warstwy do modelu, używając metody add(). W ten sposób tworzymy model sieci neuronowej, który można trenować i oceniać na danych."
      ],
      "metadata": {
        "id": "_PhYsfWcL9B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "\n",
        "# Ten fragment kodu dodaje do modelu sekwencyjnego warstwę Dense z biblioteki TensorFlow Keras.\n",
        "# Dense to klasa, która reprezentuje w pełni połączoną (ang. fully connected) warstwę sieci neuronowej, w której każdy neuron z poprzedniej warstwy jest połączony z każdym neuronem w kolejnej warstwie.\n",
        "# Argument units=6 określa liczbę neuronów w warstwie. W tym przypadku warstwa będzie miała 6 neuronów.\n",
        "# Argument activation='relu' określa funkcję aktywacji, która będzie stosowana w warstwie. W tym przypadku funkcją aktywacji jest ReLU (Rectified Linear Unit), która zwraca wartość maksymalną z zera i argumentu funkcji. Jest to jedna z popularnych funkcji aktywacji stosowanych w sieciach neuronowych.\n",
        "# Dodanie tej warstwy do modelu sekwencyjnego powoduje, że wyjście poprzedniej warstwy staje się wejściem do nowo dodanej warstwy. W ten sposób można budować sieci neuronowe o złożonej strukturze, w których każda kolejna warstwa przetwarza wynik poprzedniej warstwy."
      ],
      "metadata": {
        "id": "jhVl6D8rM6fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "VGCPFI7IObqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Ten fragment kodu dodaje do modelu sekwencyjnego kolejną warstwę Dense z biblioteki TensorFlow Keras.\n",
        "# W tym przypadku argument units=1 określa liczbę neuronów w warstwie, co oznacza, że wyjście z tej warstwy będzie składać się z jednej wartości.\n",
        "# Argument activation='sigmoid' określa funkcję aktywacji, która będzie stosowana w warstwie. W tym przypadku funkcją aktywacji jest sigmoida, która zwraca wartość w zakresie [0,1]. Jest to popularna funkcja aktywacji stosowana w warstwach wyjściowych sieci neuronowych, gdy chcemy uzyskać wynik w postaci prawdopodobieństwa.\n",
        "# W ten sposób, po dodaniu tej warstwy do modelu sekwencyjnego, otrzymujemy sieć neuronową, która przetwarza wejście i zwraca jedno wyjście w postaci wartości prawdopodobieństwa. Ta sieć neuronowa może być wykorzystana do rozwiązywania problemów binarnej klasyfikacji, gdzie chcemy przewidzieć jedną z dwóch możliwych kategorii."
      ],
      "metadata": {
        "id": "9G-v4WXTPFsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Gdybym niechciał binary, bo chce wiecej niż dwa kategorie to użyje 'categorical_crossentropy', również zmieniam 'sigmoid' na 'softmax' w Output Layer!!!\n",
        "\n",
        "# Ten fragment kodu kompiluje sieć neuronową ann utworzoną wcześniej za pomocą metody compile() z biblioteki TensorFlow Keras.\n",
        "# Argument optimizer='adam' określa algorytm optymalizacji, który będzie używany podczas trenowania sieci neuronowej. W tym przypadku używany jest algorytm Adam, który jest popularnym algorytmem optymalizacji stosowanym w sieciach neuronowych.\n",
        "# Argument loss='binary_crossentropy' określa funkcję straty (ang. loss function), która będzie minimalizowana podczas trenowania sieci neuronowej. W tym przypadku używana jest funkcja straty binarnej entropii krzyżowej, która jest popularną funkcją straty stosowaną w problemach binarnej klasyfikacji.\n",
        "# Argument metrics=['accuracy'] określa miary jakości, które będą wykorzystane do oceny wyników sieci neuronowej podczas trenowania i testowania. W tym przypadku używana jest miara dokładności (ang. accuracy), która określa procent poprawnych predykcji klasy."
      ],
      "metadata": {
        "id": "-9s9-SjsQYpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)\n",
        "\n",
        "# Ten fragment kodu trenuje sieć neuronową ann, która została utworzona wcześniej za pomocą metody fit() z biblioteki TensorFlow Keras.\n",
        "# Argument X_train i y_train to dane treningowe, które są używane do trenowania sieci neuronowej. Dane te muszą być zgodne z wymaganiami określonymi przez model sieci neuronowej.\n",
        "# Argument batch_size=32 określa rozmiar batcha, czyli liczba próbek, które są przetwarzane jednocześnie przez sieć neuronową w jednej iteracji podczas trenowania. W tym przypadku wykorzystywany jest batch o rozmiarze 32 próbek.\n",
        "# Argument epochs=100 określa liczbę epok, czyli liczbę razy, jakie sieć neuronowa będzie trenowana na całym zbiorze treningowym. W tym przypadku sieć neuronowa będzie trenowana przez 100 epok.\n",
        "# Podczas trenowania sieci neuronowej model jest optymalizowany w celu minimalizacji funkcji straty określonej podczas kompilacji sieci. Po każdej epoce wyniki są oceniane za pomocą wybranych wcześniej miar jakości, w tym przypadku dokładności (accuracy), aby sprawdzić, jak dobrze sieć neuronowa generalizuje na danych treningowych."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVGO3kjGSkI5",
        "outputId": "23b92345-fb2f-463a-af45-6c8cc26ad6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 2s 2ms/step - loss: 0.6116 - accuracy: 0.7523\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.7960\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.7964\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.7981\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4277 - accuracy: 0.8100\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4212 - accuracy: 0.8174\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4149 - accuracy: 0.8198\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4093 - accuracy: 0.8238\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4046 - accuracy: 0.8254\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4008 - accuracy: 0.8278\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3977 - accuracy: 0.8276\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3946 - accuracy: 0.8290\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3928 - accuracy: 0.8292\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3903 - accuracy: 0.8282\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3882 - accuracy: 0.8299\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3858 - accuracy: 0.8290\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8299\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3814 - accuracy: 0.8307\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3781 - accuracy: 0.8316\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3758 - accuracy: 0.8341\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3721 - accuracy: 0.8406\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3689 - accuracy: 0.8447\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8466\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3629 - accuracy: 0.8481\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3602 - accuracy: 0.8501\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3573 - accuracy: 0.8528\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3547 - accuracy: 0.8541\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3521 - accuracy: 0.8540\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3505 - accuracy: 0.8561\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8577\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8579\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8589\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8609\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8605\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.8606\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8637\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8618\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3390 - accuracy: 0.8618\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8626\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8624\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3375 - accuracy: 0.8626\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.3373 - accuracy: 0.8621\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.8626\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3365 - accuracy: 0.8609\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8637\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8633\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3360 - accuracy: 0.8641\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8633\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3356 - accuracy: 0.8634\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.8616\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8633\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8627\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8626\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8636\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.8634\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8629\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.8637\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8635\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8652\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8637\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8635\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8636\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8641\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.8646\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3327 - accuracy: 0.8622\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8639\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8634\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3324 - accuracy: 0.8631\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3324 - accuracy: 0.8624\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8633\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8641\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8624\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8659\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3311 - accuracy: 0.8637\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8651\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8641\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8641\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8643\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8645\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8659\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8635\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8633\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3310 - accuracy: 0.8644\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8635\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8640\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8651\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8652\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8649\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8644\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8652\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8655\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8655\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.8646\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3301 - accuracy: 0.8631\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3297 - accuracy: 0.8645\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3302 - accuracy: 0.8637\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3302 - accuracy: 0.8648\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3300 - accuracy: 0.8649\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3298 - accuracy: 0.8649\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3299 - accuracy: 0.8627\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe9dc3cae20>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of a single observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "**Homework**\n",
        "\n",
        "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: \\$ 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: \\$ 50000\n",
        "\n",
        "So, should we say goodbye to that customer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)\n",
        "\n",
        "# Ten fragment kodu wykorzystuje wytrenowaną sieć neuronową ann, aby dokonać predykcji na nowych danych. Do predykcji wykorzystywana jest metoda predict() z biblioteki TensorFlow Keras.\n",
        "# Argument sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]) przekształca nowe dane wejściowe do skali, która została wykorzystana podczas uczenia sieci neuronowej. W tym przypadku wykorzystywany jest wcześniej utworzony obiekt sc klasy StandardScaler z biblioteki scikit-learn.\n",
        "# Operator > 0.5 określa próg decyzyjny, powyżej którego predykcja zostanie sklasyfikowana jako pozytywna (1), a poniżej którego predykcja zostanie sklasyfikowana jako negatywna (0).\n",
        "# W tym przypadku wynik predykcji jest wyświetlany w postaci wartości logicznej True lub False, w zależności od wyniku porównania z progiem decyzyjnym."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_Wz5ufzUIWY",
        "outputId": "2952508c-2ed4-4149-c599-1145bb14627b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 320ms/step\n",
            "[[False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKX-BGxsV8az",
        "outputId": "617109f4-11c5-4f1a-ada0-a1df19e3c897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdVdw6HNWBDT",
        "outputId": "bf592a91-ee34-42f4-8f49-0e6107828703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1501   94]\n",
            " [ 188  217]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.859"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}